{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Intro to AI 4 - CW3 Artifical Neural Networks (ANN)",
   "id": "93b007e9ba84b286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup",
   "id": "e513289cc6560913"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Set up seeds (reproduceability)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"CUDA available. Using device: \", torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"CUDA is not available. Using device: \", torch.device(\"cpu\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data import",
   "id": "64a434db06836a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_PATH = r\"./interest-rates/index.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head())"
   ],
   "id": "8bd52e6ac8e2507e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_quarterly_data(df_in: pd.DataFrame, add_lags: bool = False, max_lag: int = 2):\n",
    "    target_col = \"Real GDP (Percent Change)\"\n",
    "    base_feature_cols = [\n",
    "        \"Effective Federal Funds Rate\",\n",
    "        \"Unemployment Rate\",\n",
    "        \"Inflation Rate\",\n",
    "    ]\n",
    "\n",
    "    # using a copy of the data\n",
    "    temp = df_in.copy()\n",
    "    temp = temp.set_index(\"date\").sort_index()\n",
    "\n",
    "    # FF between GDP and keep only relevant\n",
    "    temp[target_col] = temp[target_col].ffill()\n",
    "    cols_to_keep = [target_col] + base_feature_cols\n",
    "    temp = temp[cols_to_keep]\n",
    "\n",
    "    # Interpolate features in time, then back-fill any remaining NAs\n",
    "    temp[base_feature_cols] = temp[base_feature_cols].interpolate(method=\"time\")\n",
    "    temp[base_feature_cols] = temp[base_feature_cols].bfill()\n",
    "\n",
    "    df_q = temp.resample(\"QS\", label=\"left\").mean()\n",
    "\n",
    "    # create feature lags on this quarterly index.\n",
    "    feature_cols = base_feature_cols.copy()\n",
    "\n",
    "    if add_lags:\n",
    "        for col in base_feature_cols:\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                lag_name = f\"{col}_lag{lag}q\"\n",
    "                df_q[lag_name] = df_q[col].shift(lag)\n",
    "                feature_cols.append(lag_name)\n",
    "\n",
    "        df_q = df_q.dropna(subset=feature_cols + [target_col]) # Drop rows with inital NAs from the lags\n",
    "\n",
    "    return df_q, feature_cols\n"
   ],
   "id": "fbd897b8ead5d262",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# quarterly data with lags\n",
    "pipeline_input_down_lag, feature_cols_down_lag = prepare_quarterly_data(\n",
    "    df, add_lags=True, max_lag=2\n",
    ")\n",
    "\n",
    "print(\"Downsampled quarterly + feature lags shape:\", pipeline_input_down_lag.shape)\n",
    "\n",
    "display(pipeline_input_down_lag.head())"
   ],
   "id": "b017802adc750f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "data = pipeline_input_down_lag.sort_index()\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio   = 0.15\n",
    "\n",
    "N = len(data)\n",
    "\n",
    "train_end = int(N * train_ratio)\n",
    "val_end   = int(N * (train_ratio + val_ratio))\n",
    "\n",
    "#Split!\n",
    "train_df = data.iloc[:train_end]\n",
    "val_df   = data.iloc[train_end:val_end]\n",
    "test_df  = data.iloc[val_end:]\n",
    "\n",
    "X_train = train_df[feature_cols_down_lag].values.astype(np.float32)\n",
    "y_train = train_df[\"Real GDP (Percent Change)\"].values.astype(np.float32)\n",
    "\n",
    "X_val   = val_df[feature_cols_down_lag].values.astype(np.float32)\n",
    "y_val   = val_df[\"Real GDP (Percent Change)\"].values.astype(np.float32)\n",
    "\n",
    "X_test  = test_df[feature_cols_down_lag].values.astype(np.float32)\n",
    "y_test  = test_df[\"Real GDP (Percent Change)\"].values.astype(np.float32)\n",
    "\n"
   ],
   "id": "5922fa56de76ce49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Standardisation",
   "id": "a569e6c75ade9fac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# aplly transformation to all other feature sets\n",
    "X_train_scaled = scaler.transform(X_train).astype(np.float32)\n",
    "X_val_scaled   = scaler.transform(X_val).astype(np.float32)\n",
    "X_test_scaled  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# Pytorch dataset class\n",
    "class ff_dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        # Ensure y is always shape (N, 1)\n",
    "        if len(y.shape) == 1:              # shape (N,)\n",
    "            y = y.reshape(-1, 1)           # -> shape (N, 1)\n",
    "\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_dataset = ff_dataset(X_train_scaled, y_train)\n",
    "val_dataset   = ff_dataset(X_val_scaled, y_val)\n",
    "test_dataset  = ff_dataset(X_test_scaled, y_test)"
   ],
   "id": "b6613e621b85eb8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Batches\n",
    "\n",
    "With another helper function so that I can use it later in hyperparameter tuning"
   ],
   "id": "61829f96d50c352e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 16\n",
    "\n",
    "def loaders_w_batch_size(batch_size):\n",
    "    train_dataset = ff_dataset(X_train_scaled, y_train)\n",
    "    val_dataset   = ff_dataset(X_val_scaled,   y_val)\n",
    "    test_dataset  = ff_dataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = loaders_w_batch_size(batch_size)"
   ],
   "id": "41add6bde69081f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Helper functions\n",
    "\n",
    "I'll use these later for training, evaluating and plotting the model."
   ],
   "id": "4555a63d19b48ef2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, optimiser, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        batch_size = X_batch.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        n_samples += batch_size\n",
    "\n",
    "    return running_loss / n_samples\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            batch_size = X_batch.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            n_samples += batch_size\n",
    "\n",
    "    return running_loss / n_samples\n",
    "\n",
    "def plot_loss_curves(train_losses, val_losses, model_name=\"Model\"):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss (MSE)\", linewidth=2)\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss (MSE)\", linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss (MSE)\", fontsize=12)\n",
    "    plt.title(f\"{model_name} Loss Curves\", fontsize=14)\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "768e9024df8c847e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Baseline MLP Model\n",
    "\n",
    "#### Model definition"
   ],
   "id": "3ee7899010d93e95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_dim = X_train_scaled.shape[1]   # define training features size\n",
    "output_dim = 1                        # only output we want is GDP\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation_name=\"relu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # Choose activation\n",
    "        if activation_name.lower() == \"relu\":\n",
    "            act = nn.ReLU()\n",
    "        elif activation_name.lower() == \"tanh\":\n",
    "            act = nn.Tanh()\n",
    "        elif activation_name.lower() in [\"leaky_relu\", \"leaky-relu\", \"lrelu\"]:\n",
    "            act = nn.LeakyReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation_name: {activation_name}\")\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, 16),\n",
    "            act,\n",
    "            nn.Linear(16, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = BaselineMLP(input_dim, output_dim).to(device)\n",
    "print(model)\n"
   ],
   "id": "405beaa6c8e7998a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loss function and optimiser",
   "id": "8486e252c6c777e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "id": "2216e3b831fe5eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Training and evaluation helper functions\n",
    "\n",
    "These functions can be used with any of the models and will be reused when running through other non-baseline models too."
   ],
   "id": "6ef225765747d962"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e386407834ab4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training loop",
   "id": "a394ec44e05cc87d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs = 200 # max number of epochs\n",
    "patience = 20  # if validation loss doesnt improve after this many epochs, stop.\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimiser, criterion, device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"[Baseline] Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss - 1e-6:  # check for improvement accounting for potential noise\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"[Baseline] Early stopping triggered after {epoch} epochs.\")\n",
    "        break\n",
    "\n",
    "# load best model weights\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"[Baseline] Loaded best model (lowest val MSE).\")\n",
    "\n",
    "test_mse = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\n[Baseline] Final Test MSE (Baseline MLP): {test_mse:.6f}\")\n",
    "\n",
    "plot_loss_curves(train_losses, val_losses, \"Baseline MLP\")\n"
   ],
   "id": "11006417130d7354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The baseline MLP model therefore shows an MSE of around 25, translating to around 4-6 % points. This therefore is not great but works as a good baseline for the model to be developed onto, which is what will be done with the next models. The high MSE value shows that quite a bit of underfitting is taking place in this model. However, before taking this as the baseline's best performance, I will attempt to tune the hyperparameters before moving onto model B",
   "id": "3e60eebb8c0ad45e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Baseline MLP tuning\n",
    "\n",
    "In the code block below I will perform the hyperparameter tuning for the baseline MLP model. This will reuse a lot of the code above (I've decided to keep that above split up for understanding/explanation reasons)."
   ],
   "id": "df0736d68a606ca2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:45:31.539358Z",
     "start_time": "2025-12-10T17:45:31.535354Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Model running function"
   ],
   "id": "2c0a51fabd704fac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_modelA(learning_rate,\n",
    "               batch_size,\n",
    "               weight_decay,\n",
    "               activation_name,\n",
    "               num_epochs=200,\n",
    "               patience=20,\n",
    "               extra_info=False,\n",
    "               evaluate_model=False):\n",
    "\n",
    "    # new model for each run\n",
    "    model = BaselineMLP(input_dim, output_dim, activation_name=activation_name).to(device)\n",
    "\n",
    "    # create loaders\n",
    "    train_loader, val_loader, test_loader = loaders_w_batch_size(batch_size)\n",
    "\n",
    "    criterion  = nn.MSELoss()\n",
    "    optimiser  = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_loss      = float(\"inf\")\n",
    "    best_train_loss    = float(\"inf\")\n",
    "    best_model_state = None\n",
    "    epochs_no_improve  = 0\n",
    "\n",
    "    if evaluate_model:\n",
    "        train_losses = []  # only used if evaluate_model=True\n",
    "        val_losses   = []  # only used if evaluate_model=True\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimiser, criterion, device)\n",
    "        val_loss   = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        if evaluate_model:\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        if extra_info:\n",
    "            print(\n",
    "                f\"[Baseline tuning] (lr={learning_rate}, bs={batch_size}, \"\n",
    "                f\"wd={weight_decay}, act={activation_name}) \"\n",
    "                f\"Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-6:  # check for improvement accounting for potential noise\n",
    "            best_val_loss   = val_loss\n",
    "            best_model_state_B = model_B.state_dict()\n",
    "            best_train_loss = train_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "\n",
    "\n",
    "    if best_model_state_B is not None:\n",
    "        model_B.load_state_dict(best_model_state_B)\n",
    "\n",
    "    if evaluate_model:\n",
    "        test_mse = evaluate(model, test_loader, criterion, device)\n",
    "        return val_losses, train_losses, test_mse\n",
    "\n",
    "    return best_val_loss, best_train_loss\n"
   ],
   "id": "4e9b8a17eb6669cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hypereparameter grid search",
   "id": "7569fc99c2af8e3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learning_rate_grid = [1e-2, 3e-3, 1e-3]\n",
    "batch_size_grid    = [16]\n",
    "weight_decay_grid  = [0.0, 1e-4, 1e-3]\n",
    "activation_grid    = [\"relu\", \"tanh\", \"leaky_relu\"]\n",
    "\n",
    "hyperparameter_grid = list(itertools.product(\n",
    "    learning_rate_grid,\n",
    "    batch_size_grid,\n",
    "    weight_decay_grid,\n",
    "    activation_grid,\n",
    "))\n",
    "\n",
    "print(f\"[Baseline tuning] Total combinations to test for Model A: {len(hyperparameter_grid)}\")\n",
    "\n",
    "n_runs_per_setting = 3  # evaluate each hyperparameter set 3 times\n",
    "\n",
    "results = []\n",
    "\n",
    "for learning_rate, batch_size, weight_decay, activation_name in hyperparameter_grid:\n",
    "    val_mses   = []\n",
    "    train_mses = []\n",
    "\n",
    "    for run_idx in range(n_runs_per_setting):\n",
    "        # Optional: vary seed for each repeat\n",
    "        torch.manual_seed(42 + run_idx)\n",
    "        np.random.seed(42 + run_idx)\n",
    "        random.seed(42 + run_idx)\n",
    "\n",
    "        best_val_mse, best_train_mse = run_modelA(\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            weight_decay=weight_decay,\n",
    "            activation_name=activation_name,\n",
    "            num_epochs=200,\n",
    "            patience=20,\n",
    "            extra_info=False\n",
    "        )\n",
    "\n",
    "        val_mses.append(best_val_mse)\n",
    "        train_mses.append(best_train_mse)\n",
    "\n",
    "    mean_val_mse = float(np.mean(val_mses))\n",
    "    std_val_mse  = float(np.std(val_mses))\n",
    "\n",
    "    results.append({\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"activation\": activation_name,\n",
    "        \"mean_best_val_mse\": mean_val_mse,\n",
    "        \"std_best_val_mse\": std_val_mse,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"[Baseline tuning] Done: lr={learning_rate}, bs={batch_size}, \"\n",
    "        f\"wd={weight_decay}, act={activation_name} \"\n",
    "        f\"-> mean best val MSE = {mean_val_mse:.4f} (std={std_val_mse:.4f})\"\n",
    "    )\n",
    "\n",
    "results_df_A = pd.DataFrame(results)\n",
    "display(results_df_A.sort_values(\"mean_best_val_mse\").head(10))\n"
   ],
   "id": "2c2aa07a1631a9bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Analyse tuning results and evaluate best model\n",
    "The following code will use the top row of the output table (sorted by best val MSE) and use that to retrain and evaluate that specific model."
   ],
   "id": "4a9bd49de0d89a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_row_A = results_df_A.sort_values(\"mean_best_val_mse\").iloc[0]\n",
    "\n",
    "best_lr  = float(best_row_A[\"learning_rate\"])\n",
    "best_bs  = int(best_row_A[\"batch_size\"])\n",
    "best_wd  = float(best_row_A[\"weight_decay\"])\n",
    "best_act = str(best_row_A[\"activation\"])\n",
    "\n",
    "print(\"[Baseline tuning] Best hyperparameters:\")\n",
    "print(f\"  lr        = {best_lr}\")\n",
    "print(f\"  batch_size= {best_bs}\")\n",
    "print(f\"  weight_decay = {best_wd}\")\n",
    "print(f\"  activation   = {best_act}\")\n",
    "\n",
    "model_A_val_losses, model_A_train_losses, model_A_tuned_test_mse = run_modelA(\n",
    "    learning_rate=best_lr,\n",
    "    batch_size=best_bs,\n",
    "    weight_decay=best_wd,\n",
    "    activation_name=best_act,\n",
    "    evaluate_model=True,\n",
    "    extra_info=True\n",
    ")\n",
    "\n",
    "print(f\"\\n[Baseline tuning] Final Tuned Test MSE (Baseline MLP): {model_A_tuned_test_mse:.6f}\")\n",
    "\n",
    "plot_loss_curves(model_A_train_losses, model_A_val_losses, \"Baseline MLP (Tuned)\")\n"
   ],
   "id": "8ac1964ce8285939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This hyperparameter tuned model (using LR=0.01, BS=8, WD=0.0001) has the best performance, and results in a test MSE of 18, improved from 25 without tuning.",
   "id": "95da464d8f82b32c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Wider + Deeper (Model B)\n",
    "\n",
    "#### Class definition"
   ],
   "id": "31069695e7ec43d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Wider_Deeper_MLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, 32),  # hidden layer (wider)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),           # hidden layer (deeper)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, out_features)  # output layer\n",
    "        )\n",
    "\n",
    "        # He (Kaiming) initialisation for ReLU layers\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model_B = Wider_Deeper_MLP(input_dim, output_dim).to(device)\n",
    "print(model_B)"
   ],
   "id": "c846713e06dbd965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loss function and optimiser",
   "id": "b73649e2911082b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion_B = nn.MSELoss()\n",
    "optimiser_B = optim.Adam(model_B.parameters(), lr=1e-3)"
   ],
   "id": "e62578473ccbae97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training loop",
   "id": "2e286bec7d6b796e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs_B = 200 # max number of epochs\n",
    "patience_B = 20  # if validation loss doesnt improve after this many epochs, stop.\n",
    "\n",
    "best_val_loss_B = float(\"inf\")\n",
    "best_model_state_B = None\n",
    "epochs_no_improve_B = 0\n",
    "\n",
    "train_losses_B = []\n",
    "val_losses_B = []\n",
    "\n",
    "for epoch in range(1, num_epochs_B + 1):\n",
    "    train_loss = train_one_epoch(model_B, train_loader, optimiser_B, criterion_B, device)\n",
    "    val_loss = evaluate(model_B, val_loader, criterion_B, device)\n",
    "\n",
    "    train_losses_B.append(train_loss)\n",
    "    val_losses_B.append(val_loss)\n",
    "\n",
    "    print(f\"[Model B] Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss_B - 1e-6:  # check for improvement accounting for potential noise\n",
    "        best_val_loss_B = val_loss\n",
    "        best_model_state_B = model_B.state_dict()\n",
    "        epochs_no_improve_B = 0\n",
    "    else:\n",
    "        epochs_no_improve_B += 1\n",
    "\n",
    "    if epochs_no_improve_B >= patience_B:\n",
    "        print(f\"[Model B] Early stopping triggered after {epoch} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load best model weights for Model B\n",
    "if best_model_state_B is not None:\n",
    "    model_B.load_state_dict(best_model_state_B)\n",
    "    print(\"[Model B] Loaded best model (lowest val MSE).\")\n",
    "\n",
    "test_mse_B = evaluate(model_B, test_loader, criterion_B, device)\n",
    "print(f\"\\n[Model B] Final Test MSE: {test_mse_B:.6f}\")\n",
    "plot_loss_curves(train_losses_B, val_losses_B, \"Wider + Deeper MLP\")\n"
   ],
   "id": "236ae61da39178b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Wider + Deeper MLP (Model B) Tuning\n",
    "\n",
    "(Similar hyperparameters as Model A, uses modified code from model A tuning)"
   ],
   "id": "9b8f42a03bb36cac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model running function",
   "id": "40ec72aee3074305"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_modelB(learning_rate,batch_size,weight_decay, num_epochs=200, patience=20, extra_info=False, evaluate_model=False):\n",
    "\n",
    "    # new model for each run\n",
    "    model = Wider_Deeper_MLP(input_dim, output_dim).to(device)\n",
    "\n",
    "    # create loaders\n",
    "    train_loader, val_loader, test_loader = loaders_w_batch_size(batch_size)\n",
    "\n",
    "    criterion  = nn.MSELoss()\n",
    "    optimiser  = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_train_loss = float(\"inf\")\n",
    "    best_model_state = None\n",
    "    epochs_no_improve  = 0\n",
    "\n",
    "    if evaluate_model:\n",
    "        train_losses = [] # only used if evaluate_model=True\n",
    "        val_losses = []  # only used if evaluate_model=True\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimiser, criterion, device)\n",
    "        val_loss   = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        if evaluate_model:\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        if extra_info:\n",
    "            print(\n",
    "                f\"[Model B tuning] (lr={learning_rate}, bs={batch_size}, wd={weight_decay}) \"\n",
    "                f\"Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-6: # check for improvement accounting for potential noise\n",
    "            best_val_loss     = val_loss\n",
    "            best_train_loss   = train_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    # Load best model weights for Model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"[Model B] Loaded best model (lowest val MSE).\")\n",
    "\n",
    "    if evaluate_model:\n",
    "        test_mse = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        return val_losses, train_losses, test_mse\n",
    "\n",
    "    return best_val_loss, best_train_loss"
   ],
   "id": "ef2994b1e5547249",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameter Grid Search",
   "id": "89920d847f44f475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learning_rate_grid_B = [1e-2, 3e-3, 1e-3]\n",
    "batch_size_grid_B    = [8, 16]\n",
    "weight_decay_grid_B  = [0.0, 1e-4, 1e-3]\n",
    "\n",
    "hyperparameter_grid_B = list(itertools.product(\n",
    "    learning_rate_grid_B,\n",
    "    batch_size_grid_B,\n",
    "    weight_decay_grid_B,\n",
    "))\n",
    "\n",
    "print(f\"Total combinations to test for Model B: {len(hyperparameter_grid_B)}\")\n",
    "\n",
    "results_B = []\n",
    "\n",
    "for learning_rate, batch_size, weight_decay in hyperparameter_grid_B:\n",
    "    best_val_mse, best_train_mse = run_modelB(\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        weight_decay=weight_decay,\n",
    "        num_epochs=200,\n",
    "        patience=20\n",
    "    )\n",
    "\n",
    "    results_B.append({\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"best_val_mse\": best_val_mse,\n",
    "        \"train_mse_at_best_val\": best_train_mse,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"[Model B tuning] Done: lr={learning_rate}, bs={batch_size}, wd={weight_decay} \"\n",
    "        f\"-> best val MSE = {best_val_mse:.4f}\"\n",
    "    )\n",
    "\n",
    "results_df_B = pd.DataFrame(results_B)\n",
    "display(results_df_B.sort_values(\"best_val_mse\").head(10))"
   ],
   "id": "40cbe6f029ce4ffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best tune plotter",
   "id": "a5b8a3b433739ca3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_row_B = results_df_B.sort_values(\"best_val_mse\").iloc[0]\n",
    "\n",
    "best_lr_B = float(best_row_B[\"learning_rate\"])\n",
    "best_bs_B = int(best_row_B[\"batch_size\"])\n",
    "best_wd_B = float(best_row_B[\"weight_decay\"])\n",
    "\n",
    "model_B_val_losses, model_B_train_losses, model_B_tuned_test_mse = run_modelB(best_lr_B, best_bs_B, best_wd_B, evaluate_model=True, extra_info=True)\n",
    "print(f\"\\n[Model B tuning] Final Tuned Test MSE (Wider + Deeper MLP): {model_B_tuned_test_mse:.6f}\")\n",
    "\n",
    "plot_loss_curves(model_B_train_losses, model_B_val_losses, \"Wider + Deeper (Tuned)\")\n"
   ],
   "id": "11183b732ff328c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regularisation MLP (Model C)",
   "id": "cbd23d802217cc7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Class definition",
   "id": "6bb5bb9a4ccdaa24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class regularisation_MLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(16, out_features),\n",
    "        )\n",
    "\n",
    "        # He (Kaiming) initialisation for ReLU layers\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model_C = regularisation_MLP(input_dim, output_dim).to(device)\n",
    "print(model_C)\n"
   ],
   "id": "73c2ddb5faff3232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loss function and Optimisation",
   "id": "aeb2adecce844b87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion_C = nn.MSELoss()\n",
    "optimiser_C = optim.Adam(model_C.parameters(), lr=1e-3)"
   ],
   "id": "dc008a4bb7df081d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training Loop",
   "id": "19341a80d0ed403a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs_C = 200 # max number of epochs\n",
    "patience_C = 20  # if validation loss doesnt improve after this many epochs, stop.\n",
    "\n",
    "best_val_loss_C = float(\"inf\")\n",
    "best_model_state_C = None\n",
    "epochs_no_improve_C = 0\n",
    "\n",
    "train_losses_C = []\n",
    "val_losses_C = []\n",
    "\n",
    "for epoch in range(1, num_epochs_C + 1):\n",
    "    train_loss = train_one_epoch(model_C, train_loader, optimiser_C, criterion_C, device)\n",
    "    val_loss = evaluate(model_C, val_loader, criterion_C, device)\n",
    "\n",
    "    train_losses_C.append(train_loss)\n",
    "    val_losses_C.append(val_loss)\n",
    "\n",
    "    print(f\"[Model C] Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss_C - 1e-6:  # check for improvement accounting for potential noise\n",
    "        best_val_loss_C = val_loss\n",
    "        best_model_state_C = model_C.state_dict()\n",
    "        epochs_no_improve_C = 0\n",
    "    else:\n",
    "        epochs_no_improve_C += 1\n",
    "\n",
    "    if epochs_no_improve_C >= patience_C:\n",
    "        print(f\"[Model C] Early stopping triggered after {epoch} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load best model weights for Model C\n",
    "if best_model_state_C is not None:\n",
    "    model_C.load_state_dict(best_model_state_C)\n",
    "    print(\"[Model C] Loaded best model (lowest val MSE).\")\n",
    "\n",
    "test_mse_C = evaluate(model_C, test_loader, criterion_C, device)\n",
    "print(f\"\\n[Model C] Final Test MSE: {test_mse_C:.6f}\")\n",
    "plot_loss_curves(train_losses_C, val_losses_C, \"Wider + Deeper MLP\")\n"
   ],
   "id": "ebe74f0009153e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regularisation MLP Tuning",
   "id": "40ebc846ecee3f2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model running function",
   "id": "64d50dda21ef9456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_modelC(learning_rate, batch_size, weight_decay, dropout_p,\n",
    "                          num_epochs=200, patience=20, extra_info=False, evaluate_model=False):\n",
    "    \"\"\"\n",
    "    Train Model C (ModelC_MLP) with a specific set of hyperparameters and\n",
    "    return the best validation MSE and corresponding training MSE.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fresh Model C for this run (same architecture as Model B, but with dropout)\n",
    "    model_C = regularisation_MLP(input_dim, output_dim, dropout_p=dropout_p).to(device)\n",
    "\n",
    "    # Fresh loaders in case batch size changes\n",
    "    train_loader, val_loader, test_loader = loaders_w_batch_size(batch_size)\n",
    "\n",
    "    criterion  = nn.MSELoss()\n",
    "    optimiser  = optim.Adam(\n",
    "        model_C.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    best_val_loss      = float(\"inf\")\n",
    "    best_train_loss    = float(\"inf\")\n",
    "    best_model_state   = None\n",
    "    epochs_no_improve  = 0\n",
    "\n",
    "    if evaluate_model:\n",
    "        train_losses = [] # only used if evaluate_model=True\n",
    "        val_losses = []  # only used if evaluate_model=True\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model_C, train_loader, optimiser, criterion, device)\n",
    "        val_loss   = evaluate(model_C, val_loader, criterion, device)\n",
    "\n",
    "        if evaluate_model:\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        if extra_info:\n",
    "            print(\n",
    "                f\"[Model C tuning] (lr={learning_rate}, bs={batch_size}, wd={weight_decay}, p={dropout_p} \"\n",
    "                f\"Epoch {epoch:03d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "        # Early stopping based on validation loss\n",
    "        if val_loss < best_val_loss - 1e-6:  # small delta to avoid floating-point noise\n",
    "            best_val_loss     = val_loss\n",
    "            best_train_loss   = train_loss\n",
    "            best_model_state  = model_C.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    # Optionally reload best weights if you want to reuse the model afterwards\n",
    "    if best_model_state is not None:\n",
    "        model_C.load_state_dict(best_model_state)\n",
    "\n",
    "    if evaluate_model:\n",
    "        test_mse = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        return val_losses, train_losses, test_mse\n",
    "\n",
    "    return best_val_loss, best_train_loss"
   ],
   "id": "ce8e2a3a7a9e52df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameter Grid",
   "id": "78d08803748525e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learning_rate_grid_C = [1e-3, 3e-4]\n",
    "batch_size_grid_C    = [8, 16]\n",
    "weight_decay_grid_C  = [0.0, 1e-4]\n",
    "dropout_grid_C       = [0.1, 0.2, 0.3]\n",
    "\n",
    "hyperparameter_grid_C = list(itertools.product(\n",
    "    learning_rate_grid_C,\n",
    "    batch_size_grid_C,\n",
    "    weight_decay_grid_C,\n",
    "    dropout_grid_C,\n",
    "))\n",
    "\n",
    "print(f\"Total combinations to test for Model C: {len(hyperparameter_grid_C)}\")\n",
    "\n",
    "results_C = []\n",
    "\n",
    "for learning_rate, batch_size, weight_decay, dropout_p in hyperparameter_grid_C:\n",
    "    best_val_mse, best_train_mse = run_modelC(\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        weight_decay=weight_decay,\n",
    "        dropout_p=dropout_p,\n",
    "        num_epochs=200,\n",
    "        patience=20\n",
    "    )\n",
    "\n",
    "    results_C.append({\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"dropout_p\": dropout_p,\n",
    "        \"best_val_mse\": best_val_mse,\n",
    "        \"train_mse_at_best_val\": best_train_mse,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"[Model C tuning] Done: lr={learning_rate}, bs={batch_size}, wd={weight_decay}, p={dropout_p} \"\n",
    "        f\"-> best val MSE = {best_val_mse:.4f}\"\n",
    "    )\n",
    "\n",
    "results_df_C = pd.DataFrame(results_C)\n",
    "display(results_df_C.sort_values(\"best_val_mse\").head(10))"
   ],
   "id": "3ee88decec615134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best tune plotter",
   "id": "22033841f10f0713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_row_C = results_df_C.sort_values(\"best_val_mse\").iloc[0]\n",
    "\n",
    "best_lr_C = float(best_row_C[\"learning_rate\"])\n",
    "best_bs_C = int(best_row_C[\"batch_size\"])\n",
    "best_wd_C = float(best_row_C[\"weight_decay\"])\n",
    "best_do_C = float(best_row_C[\"dropout_p\"])\n",
    "\n",
    "model_C_val_losses, model_C_train_losses, model_C_tuned_test_mse = run_modelC(best_lr_C, best_bs_C, best_wd_C, best_do_C, evaluate_model=True, extra_info=True)\n",
    "print(f\"\\n[Regularisation tuning] Final Tuned Test MSE (Regularisation MLP): {model_C_tuned_test_mse:.6f}\")\n",
    "\n",
    "plot_loss_curves(model_C_train_losses, model_C_val_losses, \"Regularisation (Tuned)\")\n"
   ],
   "id": "67a431748342a0b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
